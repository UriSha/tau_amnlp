{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTIONS:\n",
    "* to(device)?\n",
    "* Low loss, bad acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader\n",
    "import evaluation\n",
    "\n",
    "raw_dataset, tokens_vocab, y_vocab = data_loader.load_raw_data(S=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "print(raw_dataset['int_sentences'][idx])\n",
    "print(raw_dataset['str_sentences'][idx])\n",
    "print(raw_dataset['int_labels'][idx])\n",
    "print(raw_dataset['str_labels'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "class WSDModel(nn.Module):\n",
    "    def __init__(self, V, Y, D=300):\n",
    "        super(WSDModel, self).__init__()\n",
    "        self.E_v = nn.Embedding(V, D)\n",
    "        self.E_y = nn.Embedding(Y, D)\n",
    "        \n",
    "#         self.W_A = nn.Parameter(torch.randn(D, D, requires_grad=True, device=device))\n",
    "#         self.W_O = nn.Parameter(torch.randn(D, D, requires_grad=True, device=device))\n",
    "        \n",
    "        self.W_A = nn.Parameter(torch.Tensor(D, D))\n",
    "        self.W_O = nn.Parameter(torch.Tensor(D, D))\n",
    "        \n",
    "        self.linear_in = nn.Linear(D, D, bias=False)\n",
    "        self.linear_out = nn.Linear(D * 2, D, bias=False)\n",
    "        \n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def attention(self, X, Q):\n",
    "        # X: [B, N, D]\n",
    "        # Q: [B, 1, D]\n",
    "\n",
    "        # A: [B, 1, N] \n",
    "        A = self.softmax(Q @ self.W_A @ X.transpose(1, 2))\n",
    "        Q_c = A @ X @ self.W_O\n",
    "        return Q_c, A\n",
    "    \n",
    "    def attention_2(self, X, Q):\n",
    "        # copied from https://pytorchnlp.readthedocs.io/en/latest/_modules/torchnlp/nn/attention.html\n",
    "        \n",
    "        B, output_len, D = Q.size()\n",
    "        N = X.size(1)\n",
    "\n",
    "        Q = Q.reshape(B * output_len, D)\n",
    "#         Q = Q @ self.W_A\n",
    "        Q = self.linear_in(Q)\n",
    "        Q = Q.reshape(B, output_len, D)\n",
    "\n",
    "        A_logits = torch.bmm(Q, X.transpose(1, 2).contiguous())\n",
    "\n",
    "        # Compute weights across every context sequence\n",
    "        A_logits = A_logits.view(B * output_len, N)\n",
    "        A = self.softmax(A_logits)\n",
    "        A = A.view(B, output_len, N)\n",
    "\n",
    "        # (batch_size, output_len, query_len) * (batch_size, query_len, dimensions) ->\n",
    "        # (batch_size, output_len, dimensions)\n",
    "        mix = torch.bmm(A, X)\n",
    "\n",
    "        # concat -> (batch_size * output_len, 2*dimensions)\n",
    "        combined = torch.cat((mix, Q), dim=2)\n",
    "        combined = combined.view(B * output_len, 2 * D)\n",
    "\n",
    "        # Apply linear_out on every 2nd dimension of concat\n",
    "        # output -> (batch_size, output_len, dimensions)\n",
    "#         output = (combined @ self.W_O_2).view(B, output_len, D)\n",
    "        output = self.linear_out(combined).view(B, output_len, D)\n",
    "        output = self.tanh(output)\n",
    "\n",
    "        return output, A\n",
    "    \n",
    "    def forward(self, M_s, v_q):\n",
    "        # M_s: [B, N]\n",
    "        # v_q: [B]\n",
    "        \n",
    "        X = self.E_v(M_s)\n",
    "        \n",
    "        # TODO: https://pytorch.org/docs/stable/torch.html#torch.gather\n",
    "        Q_idxs = M_s[range(v_q.shape[0]), v_q]\n",
    "        Q = self.E_v(Q_idxs).unsqueeze(1)\n",
    "\n",
    "        Q_c, A = self.attention(X, Q)\n",
    "#         Q_c, A = self.attention_2(X, Q)\n",
    "        \n",
    "        H = F.relu(Q_c + Q)\n",
    "        y_logits = (H @ self.E_y.weight.T).squeeze()\n",
    "        return y_logits, A.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsd_dataset = data_loader.WSDDataset(raw_dataset, tokens_vocab, y_vocab)\n",
    "wsd_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = tokens_vocab.size()\n",
    "Y = y_vocab.size()\n",
    "model = WSDModel(V, Y, D=50).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "B = 64\n",
    "\n",
    "training_generator = data.DataLoader(\n",
    "    wsd_dataset, \n",
    "    batch_size=B, \n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "losses = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    with tqdm(training_generator) as prg_train:\n",
    "        for M_s, v_q, y_true in prg_train:\n",
    "            M_s, v_q, y_true = M_s.to(device), v_q.to(device), y_true.to(device)\n",
    "\n",
    "            ## SHAPES:\n",
    "            # M_s     --> [B, N]\n",
    "            # M_q     --> [B]\n",
    "            # y_true  --> [B]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_logits, _ = model(M_s, v_q)\n",
    "#             print(y_logits.shape)\n",
    "            loss = ce_loss(y_logits, y_true)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            running_mean_loss = statistics.mean(losses[-min(len(losses), 100):])\n",
    "            status_str = f'[{epoch}] loss: {running_mean_loss:.3f}'\n",
    "            prg_train.set_description(status_str)\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            cur_train_acc = evaluation.evaluate(model, training_generator)\n",
    "            train_acc.append(cur_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, figsize=(15, 5))\n",
    "\n",
    "axs[0].plot(losses, '-');\n",
    "axs[1].plot(train_acc, '-o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('max_columns', 100)\n",
    "\n",
    "g = data.DataLoader(\n",
    "    wsd_dataset, \n",
    "    batch_size=5, \n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "acc, eval_df, attention_df = evaluation.evaluate_verbose(model, g, tokens_vocab, y_vocab, iter_lim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_styled, att_styled = evaluation.fancy_display(eval_df, attention_df)\n",
    "ev_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tau_nlp",
   "language": "python",
   "name": "tau_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
